{"cells":[{"cell_type":"markdown","id":"b5c51c42-bbfd-42f3-991d-8987b4e2a087","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Download dataset and upload to lakehouse\n","\n","Connect to Azure Open Datasets Container and load the Predictive Maintenance dataset. This code downloads a publicly available version of the dataset and then stores it in a Fabric lakehouse.\n","\n","> [!IMPORTANT]\n","> [Add a lakehouse](https://aka.ms/fabric/addlakehouse) to the notebook before running it. **Failure to do so results in an error.**"]},{"cell_type":"markdown","id":"7c5fdb1d-8a41-4dbb-a783-1a20097ce24b","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["<h5>This code downloads demo data files into a lakehouse directory if they don't already exist.</h5>\n","<hr>\n","\n","**Variables:**\n","\n","<p><i>DATA_FOLDER:</i> Name of the folder containing the dataset.<br>\n","<i>DATA_FILE:</i> Name of the data file to be downloaded.<br>\n","<i>remote_url:</i> URL where the data files are hosted.<br>\n","<i>file_list:</i> List of files to be downloaded.<br>\n","<i>download_path:</i> Path to download files into.</P>\n","\n","**File Download Process:**\n","\n","<p>It checks if the default lakehouse directory exists. If not, it raises an error.<br>\n","It creates the necessary directory structure within the lakehouse.<br>\n","Iterates through the list of files to be downloaded.<br>\n","For each file, it checks if it exists in the designated download path. If not, it downloads the file from the remote URL and writes it into the appropriate directory.</p>"]},{"cell_type":"code","execution_count":null,"id":"04d0e921-4076-4b06-b91e-5855832ac6f4","metadata":{},"outputs":[],"source":["\n","# Importing necessary libraries\n","import os,requests\n","\n","# Setting up folder and file names\n","DATA_FOLDER = \"Files/OpenFoodFactsZip/\"  # Folder containing the dataset\n","DATA_FILE = \"en.openfoodfacts.org.products.csv.gz\"  # Data file name\n","\n","# Remote URL where data files are hosted\n","remote_url = \"https://static.openfoodfacts.org/data/\"\n","\n","# List of files to be downloaded\n","file_list = [\"en.openfoodfacts.org.products.csv.gz\"]\n","\n","# Path to download files into\n","download_path = f\"/lakehouse/default/{DATA_FOLDER}/raw\"\n","\n","# Checking if default lakehouse exists, if not, raise an error\n","if not os.path.exists(\"/lakehouse/default\"):\n","    raise FileNotFoundError(\n","        \"Default lakehouse not found, please add a lakehouse and restart the session.\"\n","    )\n","\n","# Creating the directory structure if it doesn't exist\n","os.makedirs(download_path, exist_ok=True)\n","\n","# Iterating through the file list and downloading files if they don't exist\n","for fname in file_list:\n","    if not os.path.exists(f\"{download_path}/{fname}\"):\n","        # Fetching the file from the remote URL\n","        r = requests.get(f\"{remote_url}/{fname}\", timeout=30)\n","        # Writing the downloaded content into the appropriate directory\n","        with open(f\"{download_path}/{fname}\", \"wb\") as f:\n","            f.write(r.content)\n","\n","# Informing the user that files have been downloaded\n","print(\"Downloaded demo data files into lakehouse.\")"]},{"cell_type":"markdown","id":"22617072-3a23-4c7b-a99f-8e4e1b19f349","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["<h5>This code reads data from a CSV file into a Spark DataFrame using the provided options, and then displays the first 5 rows of the DataFrame.</h5>\n","<hr>\n","\n","<b>DataFrame Creation:</b>\n","\n","<p>The spark.read method is used to read data into a DataFrame.<br>\n","Various options such as header, sep (separator), and inferSchema are specified to properly read the CSV file.<br>\n","The csv method is used to read the CSV file, with the file path specified by <i>f\"{DATA_FOLDER}raw/en.openfoodfacts.org.products.csv.gz\"</i>.<br>\n","The cache method is used to cache the DataFrame in memory for faster access.\n","\n","<b>Displaying DataFrame:</b>\n","\n","The show method is used to display the first 5 rows of the DataFrame."]},{"cell_type":"code","execution_count":null,"id":"3924efa3-bd47-4bed-9373-2871d950655d","metadata":{"advisor":{"adviceMetadata":"{\"artifactId\":\"6310e8f2-6e1d-4b48-bc83-906f22e14756\",\"activityId\":\"6abce8d0-523c-4061-8c62-14d9deb51a8d\",\"applicationId\":\"application_1708077792483_0001\",\"jobGroupId\":\"6\",\"advices\":{\"info\":1}}"},"jupyter":{"outputs_hidden":true,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Reading data into a Spark DataFrame\n","df = (\n","    spark.read.option(\"header\", True)  \n","    .option(\"sep\", '\\t')  # Specifying the separator as tab\n","    .option(\"inferSchema\", True)  # Inferring the schema\n","    .csv(f\"{DATA_FOLDER}raw/en.openfoodfacts.org.products.csv.gz\")  # Reading the CSV file\n","    .cache()  # Caching the DataFrame for better performance\n",")\n","\n","# Displaying the first 5 rows of the DataFrame\n","df.show(5)"]},{"cell_type":"markdown","id":"3ebd5c50-55ce-4656-98fc-53c323f4db47","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["<h5>This code replaces spaces in the column names of the DataFrame with underscores to avoid invalid characters while saving.</h5>\n","<hr>\n","\n","<b>Column Name Replacement:</b>\n","\n","<p>It iterates over each column name in the DataFrame using a generator expression <i>(c.replace(' ', '_') for c in df.columns)</i>.<br>\n","For each column name, it replaces spaces with underscores using the replace method.<br>\n","The resulting column names are used to create a new DataFrame with updated column names.</p>\n","\n","<b>Table Name Definition:</b>\n","\n","The variable table_name is assigned the value <i>products_zip</i> to define the name of the table where the DataFrame will be saved.\n","\n","<b>Displaying DataFrame:</b>\n","\n","The show method is used to display the first 5 rows of the DataFrame after updating the column names."]},{"cell_type":"code","execution_count":null,"id":"ada10b26-6a52-4dd1-b822-47c3440f525c","metadata":{"jupyter":{"outputs_hidden":true,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Replacing spaces in column names with underscores to avoid invalid characters while saving\n","df = df.toDF(*(c.replace(' ', '_') for c in df.columns))\n","\n","# Defining the table name\n","table_name = \"products_zip\"\n","\n","# Displaying the first 5 rows of the DataFrame with updated column names\n","df.show(5)"]},{"cell_type":"markdown","id":"dfa7b156-02c8-4356-b9f2-1342b8a9afe6","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["<h5>This code saves the DataFrame with processed columns to the lakehouse in the Delta format.</h5>\n","<hr>\n","\n","<b>DataFrame Saving:</b>\n","\n","<p>The write method is used to specify the write mode as <i>overwrite</i>, which means any existing data with the same table name will be replaced.<br>\n","The format for saving the data is specified as <i>delta</i>.<br>\n","The data is saved to the path specified by <i>f\"Tables/{table_name}\"</i> .</p>\n","\n","<b>Confirmation:</b>\n","\n","After saving the DataFrame, a confirmation message is printed indicating that the Spark DataFrame has been saved to the Delta table named <i>products_zip</i>."]},{"cell_type":"code","execution_count":null,"id":"d27797c5-0698-452a-a64e-aecaa7bc9cfc","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Saving the DataFrame with processed columns to the lakehouse\n","df.write.mode(\"overwrite\").format(\"delta\").save(f\"Tables/{table_name}\")\n","\n","# Printing a confirmation message\n","print(f\"Spark dataframe saved to delta table: {table_name}\")"]}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"default_lakehouse":"37a045d0-664d-4fbf-a38b-a3a29f042681","default_lakehouse_name":"OpenFoodFacts_LH","default_lakehouse_workspace_id":"3dc52a27-0975-4ec2-a711-94205400bada"}},"widgets":{}},"nbformat":4,"nbformat_minor":5}
